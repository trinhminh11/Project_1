{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "cwd = os.getcwd()\n",
    "\n",
    "import cv2\n",
    "from deepface import DeepFace\n",
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "model = 'liveness.model'\n",
    "\n",
    "model: tf.keras.Model = tf.keras.models.load_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file(path: str):\n",
    "\tperson, s = path.split('/')[-2:]\n",
    "\ts = s.split(\".\")\n",
    "\n",
    "\tif len(s) <= 0:\n",
    "\t\traise ValueError\n",
    "\t\n",
    "\tif len(s) == 1:\n",
    "\t\treturn s[0], None\n",
    "\n",
    "\tfile_name_extension = s[-1]\n",
    "\tname = \".\".join(s[:-1])\n",
    "\n",
    "\treturn person, file_name_extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findThreshold(model_name, distance_metric):\n",
    "\n",
    "    base_threshold = {\"cosine\": 0.40, \"euclidean\": 0.55, \"euclidean_l2\": 0.75}\n",
    "\n",
    "    thresholds = {\n",
    "        \"VGG-Face\": {\"cosine\": 0.40, \"euclidean\": 0.60, \"euclidean_l2\": 0.86},\n",
    "        \"Facenet\": {\"cosine\": 0.40, \"euclidean\": 10, \"euclidean_l2\": 0.80},\n",
    "        \"Facenet512\": {\"cosine\": 0.30, \"euclidean\": 23.56, \"euclidean_l2\": 1.04},\n",
    "        \"ArcFace\": {\"cosine\": 0.68, \"euclidean\": 4.15, \"euclidean_l2\": 1.13},\n",
    "        \"Dlib\": {\"cosine\": 0.07, \"euclidean\": 0.6, \"euclidean_l2\": 0.4},\n",
    "        \"SFace\": {\"cosine\": 0.593, \"euclidean\": 10.734, \"euclidean_l2\": 1.055},\n",
    "        \"OpenFace\": {\"cosine\": 0.10, \"euclidean\": 0.55, \"euclidean_l2\": 0.55},\n",
    "        \"DeepFace\": {\"cosine\": 0.23, \"euclidean\": 64, \"euclidean_l2\": 0.64},\n",
    "        \"DeepID\": {\"cosine\": 0.015, \"euclidean\": 45, \"euclidean_l2\": 0.17},\n",
    "    }\n",
    "\n",
    "    threshold = thresholds.get(model_name, base_threshold).get(distance_metric, 0.4)\n",
    "\n",
    "    return threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_condidence(distance, threshold = 0.6):\n",
    "\trange_ = (1.0 - threshold)\n",
    "\tlinear_val = (1.0 - distance) / (range_ * 2.0)\n",
    "\n",
    "\tif distance > threshold:\n",
    "\t\treturn f'{round(linear_val * 100, 2)}%'\n",
    "\telse:\n",
    "\t\tvalue = (linear_val + ((1.0 - linear_val) * pow((linear_val - 0.5)*2, 0.2))) * 100\n",
    "\t\treturn f'{round(value, 2)}%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class App:\n",
    "\t'''\n",
    "\t\tmodel_name = [\n",
    "\t\t\t\"VGG-Face\", \n",
    "\t\t\t\"Facenet\", \n",
    "\t\t\t\"Facenet512\", \n",
    "\t\t\t\"OpenFace\", \n",
    "\t\t\t\"DeepFace\", \n",
    "\t\t\t\"DeepID\", \n",
    "\t\t\t\"ArcFace\", \n",
    "\t\t\t\"Dlib\", \n",
    "\t\t\t\"SFace\",\n",
    "\t\t]\n",
    "\n",
    "\t\tdistance_metric = [\"cosine\", \"euclidean\", \"euclidean_l2\"]\n",
    "\n",
    "\t\tdetector_backend = [\n",
    "\t\t\t'opencv', \n",
    "\t\t\t'ssd', \n",
    "\t\t\t'dlib', \n",
    "\t\t\t'mtcnn', \n",
    "\t\t\t'retinaface', \n",
    "\t\t\t'mediapipe',\n",
    "\t\t\t'yolov8',\n",
    "\t\t\t'yunet',\n",
    "\t\t\t'fastmtcnn',\n",
    "\t\t]\n",
    "\t'''\n",
    "\n",
    "\t# Path to store current frame\n",
    "\tTEMP_FILE = f'{cwd}/temp.jpg'\n",
    "\n",
    "\t# count frame\n",
    "\tcount = 0\n",
    "\n",
    "\tdef __init__(self, cam_ID: int, size, FPS: int, db_path: os.path, model_name = \"Facenet512\", distance_metric = 'cosine', detector_backend = 'opencv'):\n",
    "\n",
    "\t\t# cv2 init, get cam, set Width, Height, set FPS\n",
    "\t\tself.cam = cv2.VideoCapture(cam_ID)\n",
    "\t\tself.cam.set(cv2.CAP_PROP_FRAME_WIDTH, size[0])\n",
    "\t\tself.cam.set(cv2.CAP_PROP_FRAME_HEIGHT, size[1])\n",
    "\t\tself.cam.set(cv2.CAP_PROP_POS_FRAMES, FPS)\n",
    "\t\tself.FPS = FPS\n",
    "\n",
    "\t\t# tkinter init, make screen\n",
    "\t\tself.main_screen = tk.Tk()\n",
    "\t\tself.main_screen.geometry(f\"{size[0]+20}x{size[1]}\")\n",
    "\n",
    "\t\t# canvas to show vid\n",
    "\t\tself.webcam_label = tk.Label(self.main_screen)\n",
    "\t\tself.webcam_label.grid(row=0, column=0)\n",
    "\t\tself.webcam_label.place(x = 10, y = 0, width = size[0], height=size[1])\n",
    "\t\t\n",
    "\t\t# face data path\n",
    "\t\tself.db_path = db_path\n",
    "\n",
    "\t\t# Deepace property\n",
    "\t\tself.model_name = model_name\n",
    "\t\tself.distance_metric = distance_metric\n",
    "\t\tself.detector_backend = detector_backend\n",
    "\n",
    "\t\t# if exist, remove\n",
    "\t\tfile_name = f\"representations_{self.model_name}.pkl\"\n",
    "\t\tfile_name = file_name.replace(\"-\", \"_\").lower()\n",
    "\t\ttry:\n",
    "\t\t\tos.remove(f'{self.db_path}/{file_name}')\n",
    "\t\t\t# os.remove(self.TEMP_FILE)\n",
    "\t\texcept:\n",
    "\t\t\tpass\n",
    "\n",
    "\t\t\n",
    "\t\t# initial create represent to pickle\n",
    "\t\tif len(os.listdir(self.db_path)) > 0:\n",
    "\t\t\tDeepFace.find(f'{cwd}/_temp.jpg', self.db_path, model_name=self.model_name, distance_metric=self.distance_metric, detector_backend=self.detector_backend, silent=True)\n",
    "\t\telse:\n",
    "\t\t\tprint(\"no_data\")\n",
    "\n",
    "\t\tself.add_webcam(self.webcam_label)\n",
    "\t\n",
    "\tdef find_face(self):\n",
    "\t\t'''\n",
    "\t\tCOMPARE face in TEMP_FILE if face in db_path\n",
    "\t\traise ValueError if cannot find any face in TEMP_FILE\n",
    "\t\t'''\n",
    "\t\t\n",
    "\t\t# deepface lib\n",
    "\t\tdetect = DeepFace.find(self.TEMP_FILE, self.db_path, model_name=self.model_name, distance_metric=self.distance_metric, enforce_detection=False, detector_backend=self.detector_backend, silent=True)\n",
    "\t\tdata = []\n",
    "\n",
    "\n",
    "\t\t\n",
    "\t\tfor info in detect:\n",
    "\t\t\tif len(info['identity']) > 1:\n",
    "\t\t\t\tname1 = get_file(info['identity'][0])[0]\n",
    "\t\t\t\tname2 = get_file(info['identity'][1])[0]\n",
    "\t\t\t\tif name1 == name2:\n",
    "\t\t\t\t\tname = name1\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tname = \"Unknown\"\n",
    "\n",
    "\t\t\telse:\n",
    "\t\t\t\tname = 'Unknown'\n",
    "\n",
    "\n",
    "\t\t\tx1, y1 = info['source_x'][0], info['source_y'][0]\n",
    "\t\t\tx2, y2 = x1 + info['source_w'][0], y1 + info['source_h'][0]\n",
    "\n",
    "\t\t\t# liveness\n",
    "\t\t\t_img = cv2.imread(self.TEMP_FILE)[x1: x2, y1:y2]\n",
    "\t\t\t_img = cv2.resize(_img, (32, 32))\n",
    "\t\t\t_img = _img.astype('float')/255.0\n",
    "\t\t\t_img = tf.keras.preprocessing.image.img_to_array(_img)\n",
    "\t\t\t_img = np.expand_dims(_img, axis = 0)\n",
    "\n",
    "\t\t\tliveness = model.predict(_img, verbose=0)\n",
    "\t\t\tliveness = liveness[0].argmax()\n",
    "\t\t\t# end liveness\n",
    "\n",
    "\t\t\tdistance = info[f'{self.model_name}_{self.distance_metric}'][0]\n",
    "\t\t\tthreshold = findThreshold(self.model_name, self.distance_metric)\n",
    "\t\t\tconfidence = face_condidence(distance, threshold)\n",
    "\n",
    "\t\t\tdata.append( (name, (x1, y1), (x2, y2), confidence, liveness ))\n",
    "\n",
    "\t\treturn data\n",
    "\t\n",
    "\tdef recognition(self, frame, rec_per_frame):\n",
    "\t\t'''\n",
    "\t\tmain recognition function\n",
    "\t\t'''\n",
    "\t\t# check every {rec_per_frame} frame\n",
    "\t\tif self.count % rec_per_frame == 0:\n",
    "\t\t\tself.count = 0\n",
    "\n",
    "\t\t\t# write frame to file\n",
    "\t\t\tcv2.imwrite(self.TEMP_FILE, frame)\n",
    "\n",
    "\t\t\ttry:\n",
    "\t\t\t\tself.data = self.find_face()\n",
    "\n",
    "\t\t\texcept ValueError:\n",
    "\t\t\t\tprint(\"cant read face\")\n",
    "\n",
    "\t\t# Draw face box\n",
    "\t\tfor name, s, e, confidence, liveness in self.data:\n",
    "\t\t\tcv2.rectangle(frame, s, e, (0, 255, 0))\n",
    "\t\t\tcv2.rectangle(frame, (s[0], s[1]-40), (e[0], s[1]), (0, 255, 0), -1)\n",
    "\n",
    "\t\t\tif name == 'Unknown':\n",
    "\t\t\t\tcv2.putText(frame, f'{name}', (s[0], s[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255))\n",
    "\n",
    "\t\t\telse:\n",
    "\t\t\t\tcv2.putText(frame, f'{name}: {liveness}', (s[0], s[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255))\n",
    "\t\t\n",
    "\t\t\n",
    "\tdef add_webcam(self, label: tk.Label):\n",
    "\t\t'''\n",
    "\t\tadd cv2 to tkinter\n",
    "\t\t'''\n",
    "\t\t\n",
    "\t\tself.data = []\n",
    "\n",
    "\t\tself._label = label\n",
    "\n",
    "\t\tself.process_webcam()\n",
    "\t\n",
    "\tdef process_webcam(self):\n",
    "\t\tself.count += 1\n",
    "\n",
    "\t\t# read from cam\n",
    "\t\tret, frame = self.cam.read()\n",
    "\n",
    "\t\t# cannot grab frame\n",
    "\t\tif not ret:\n",
    "\t\t\tprint(\"failed to grab frame\")\n",
    "\t\t\texit()\n",
    "\n",
    "\t\t# main recognition function\n",
    "\t\tself.recognition(frame, 10)\n",
    "\t\t\n",
    "\t\t\n",
    "\t\t#from frame to tkinter\n",
    "\t\timg = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\t\timg = Image.fromarray(img)\n",
    "\t\timgtk = ImageTk.PhotoImage(image=img)\n",
    "\t\tself._label.imgtk = imgtk\n",
    "\t\tself._label.config(image=imgtk)\n",
    "\n",
    "\t\t# mainloop FPS\n",
    "\t\tself._label.after(self.FPS, self.process_webcam)\n",
    "\t\n",
    "\tdef run(self):\n",
    "\t\t# tkinter mainloop\n",
    "\t\tself.main_screen.mainloop()\n",
    "\t\t# exit\n",
    "\t\tself.exit()\n",
    "\t\n",
    "\n",
    "\tdef exit(self):\n",
    "\t\t'''\n",
    "\t\trelease cam and remove temp file\n",
    "\t\t'''\n",
    "\t\tself.cam.release()\n",
    "\n",
    "\t\tfile_name = f\"representations_{self.model_name}.pkl\"\n",
    "\t\tfile_name = file_name.replace(\"-\", \"_\").lower()\n",
    "\t\ttry:\n",
    "\t\t\tos.remove(f'{self.db_path}/{file_name}')\n",
    "\t\t\t# os.remove(self.TEMP_FILE)\n",
    "\t\texcept:\n",
    "\t\t\tpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\tface_reg = App(\n",
    "\t\t\tcam_ID= 1,\n",
    "\t\t\tsize= (640, 480),\n",
    "\t\t\tFPS= 30,\n",
    "\t\t\tdb_path= f'./data',\n",
    "\t\t\tmodel_name= \"ArcFace\",\n",
    "\t\t\tdistance_metric= \"cosine\",\n",
    "\t\t\tdetector_backend= \"opencv\"\n",
    "\t\t)\n",
    "\n",
    "\tface_reg.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepFace.find('temp.jpg', 'data', enforce_detection=False, model_name='Facenet', detector_backend='opencv')\n",
    "# main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
